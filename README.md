# Hackaton SOAT11 - Video Processor

AplicaÃ§Ã£o Python para processar vÃ­deos do S3, extraindo frames e gerando arquivos ZIP, com processamento paralelo via Kafka e integraÃ§Ã£o com PostgreSQL.

## ğŸ“‹ DescriÃ§Ã£o

Esta aplicaÃ§Ã£o roda um servidor FastAPI que:
- Escuta eventos do Kafka com informaÃ§Ãµes de vÃ­deos
- Gerencia processamento de vÃ­deos com banco de dados PostgreSQL
- Controla status de processamento (aguardando, processando, finalizado, erro)
- Baixa vÃ­deos do AWS S3
- Extrai frames distribuÃ­dos ao longo do vÃ­deo (inÃ­cio, meio e fim)
- Gera arquivo ZIP com as imagens
- Faz upload do ZIP no S3
- Envia mensagem de conclusÃ£o com dados do usuÃ¡rio para tÃ³pico Kafka
- **Processa mÃºltiplos vÃ­deos simultaneamente**

## ğŸš€ Funcionalidades

- âœ… **Processamento Paralelo** - Processa mÃºltiplos vÃ­deos ao mesmo tempo
- âœ… **IntegraÃ§Ã£o com PostgreSQL** - Controle de status e dados de vÃ­deos/usuÃ¡rios
- âœ… Servidor FastAPI com healthcheck para EKS/Docker
- âœ… Consumer Kafka rodando em background
- âœ… ExtraÃ§Ã£o inteligente de frames (inÃ­cio, meio e fim do vÃ­deo)
- âœ… GeraÃ§Ã£o automÃ¡tica de ZIP com frames
- âœ… Upload automÃ¡tico no S3 (pasta `zip/`)
- âœ… Producer Kafka para notificaÃ§Ã£o de conclusÃ£o com dados do usuÃ¡rio
- âœ… Tratamento de erros com atualizaÃ§Ã£o de status
- âœ… Arquitetura Hexagonal (Ports & Adapters)
- âœ… Logging detalhado por vÃ­deo
- âœ… ValidaÃ§Ã£o de configuraÃ§Ãµes
- âœ… DocumentaÃ§Ã£o automÃ¡tica (Swagger)

## ğŸ“¦ PrÃ©-requisitos

- Python 3.8+
- PostgreSQL 12+ (local ou remoto)
- Kafka rodando (local ou remoto)
- Conta AWS com acesso ao S3
- OpenCV (incluÃ­do no requirements.txt)
- Ambiente virtual Python (recomendado)

## ğŸ”§ InstalaÃ§Ã£o

1. Clone o repositÃ³rio e ative o ambiente virtual:

```powershell
cd hackaton-soat11-videoprc
.venv\Scripts\activate
```

2. Instale as dependÃªncias:

```powershell
pip install -r requirements.txt
```

3. Configure as variÃ¡veis de ambiente:

```powershell
# Copie o arquivo de exemplo
Copy-Item .env.example .env

# Edite o arquivo .env com suas configuraÃ§Ãµes
```

## âš™ï¸ ConfiguraÃ§Ã£o

Edite o arquivo `.env` com suas credenciais e configuraÃ§Ãµes:

```env
# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC=video-events              # TÃ³pico de entrada
KAFKA_OUTPUT_TOPIC=video-processed    # TÃ³pico de saÃ­da
KAFKA_GROUP_ID=video-processor-group
KAFKA_AUTO_OFFSET_RESET=earliest

# AWS S3
AWS_ACCESS_KEY_ID=sua_access_key
AWS_SECRET_ACCESS_KEY=sua_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=seu-bucket

# PostgreSQL Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=cliptozip
DB_USER=postgres
DB_PASSWORD=sua-senha

# AplicaÃ§Ã£o
LOG_LEVEL=INFO
APP_NAME=video-processor
MAX_WORKERS=3  # NÃºmero de vÃ­deos processando simultaneamente
```

## ğŸ—„ï¸ Banco de Dados

### Estrutura das Tabelas

#### Tabela: cliptozip.videos

```sql
CREATE TABLE cliptozip.videos (
    video_id uuid NOT NULL,
    user_id uuid NOT NULL,
    data_video_up timestamp DEFAULT CURRENT_TIMESTAMP NOT NULL,
    status int4 NOT NULL,
    video_name varchar(200) NULL,
    zip_name varchar(200) NULL,
    descricao varchar(500) NULL,
    titulo varchar(150) NULL,
    metadados jsonb NULL,
    CONSTRAINT videos_pkey PRIMARY KEY (video_id),
    CONSTRAINT videos_user_fk FOREIGN KEY (user_id) REFERENCES cliptozip."user"(user_id)
);
```

#### Tabela: cliptozip.user

```sql
CREATE TABLE cliptozip."user" (
    user_id uuid DEFAULT gen_random_uuid() NOT NULL,
    "name" varchar(255) NULL,
    email varchar(255) NOT NULL,
    password_hash varchar(255) NOT NULL,
    created_at timestamptz DEFAULT now() NOT NULL,
    CONSTRAINT user_pkey PRIMARY KEY (user_id)
);
CREATE INDEX idx_app_user_email ON cliptozip."user" USING btree (email);
```

### Status dos VÃ­deos

| Status | DescriÃ§Ã£o |
|--------|-----------|
| 1 | Aguardando processamento |
| 2 | Processando |
| 3 | Finalizado com sucesso |
| 4 | Erro no processamento |

## ğŸ“¨ Mensagens Kafka

### Mensagem de Entrada (TÃ³pico: video-events)

```json
{
  "video_id": "uuid-do-video",
  "path": "video/nome-do-video.mp4"
}
```

### Mensagem de SaÃ­da - Sucesso (TÃ³pico: video-processed)

```json
{
  "titulo": "Nome do vÃ­deo",
  "status": "Finalizado",
  "mensagem": "Seu zip estÃ¡ pronto para download",
  "emailUsuario": "usuario@email.com",
  "nomeUsuario": "Nome do UsuÃ¡rio"
}
```

### Mensagem de SaÃ­da - Erro (TÃ³pico: video-processed)

```json
{
  "titulo": "Nome do vÃ­deo",
  "status": "Erro",
  "mensagem": "Houve um erro no processamento do seu vÃ­deo",
  "emailUsuario": "usuario@email.com",
  "nomeUsuario": "Nome do UsuÃ¡rio"
}
```

## ğŸ”„ Fluxo de Processamento

```
ğŸ“¥ Kafka (video-events) - Recebe video_id e path
    â†“
ğŸ” Busca vÃ­deo e usuÃ¡rio no PostgreSQL pelo video_id
    â†“
âœ… Valida status = 1 (aguardando processamento)
    â†“
ğŸ”„ Atualiza status = 2 (processando)
    â†“
ğŸ“¦ Download vÃ­deo do S3
    â†“
ğŸ¬ ExtraÃ§Ã£o de 4 frames (inÃ­cio, meio, fim)
    â†“
ğŸ“¦ CriaÃ§Ã£o de arquivo ZIP com frames
    â†“
â˜ï¸ Upload do ZIP para S3 (pasta zip/)
    â†“
âœ… Sucesso: Status = 3 + salva zip_name + envia mensagem com dados do usuÃ¡rio
âŒ Erro: Status = 4 + envia mensagem de erro com dados do usuÃ¡rio
    â†“
ğŸ“¤ Kafka (video-processed) - NotificaÃ§Ã£o ao usuÃ¡rio
```

### ğŸ¯ ExtraÃ§Ã£o de Frames

Os frames sÃ£o extraÃ­dos de forma distribuÃ­da:
- **Frame 1**: InÃ­cio do vÃ­deo (frame 0)
- **Frame 2**: Meio do vÃ­deo (~33%)
- **Frame 3**: Meio-fim do vÃ­deo (~66%)
- **Frame 4**: Final do vÃ­deo (Ãºltimo frame)

Exemplo: VÃ­deo com 300 frames â†’ Extrai frames: 0, 100, 200, 299

## âš¡ Processamento Paralelo

A aplicaÃ§Ã£o utiliza **ThreadPoolExecutor** para processar mÃºltiplos vÃ­deos simultaneamente:

- Configure `MAX_WORKERS` no `.env` (padrÃ£o: 3)
- Cada vÃ­deo Ã© processado em uma thread separada
- O Consumer Kafka nÃ£o bloqueia durante o processamento
- Logs identificam qual thread estÃ¡ processando cada vÃ­deo

**Exemplo de log com processamento paralelo:**
```
INFO - ğŸ¬ [Video ID: 1] Tarefa submetida para processamento
INFO - ğŸ¬ [Video ID: 2] Tarefa submetida para processamento
INFO - ğŸ“Š Tarefas em processamento: ~2
INFO - [Thread-1] Processando vÃ­deo - Video ID: 1
INFO - [Thread-2] Processando vÃ­deo - Video ID: 2
INFO - âœ… [Video ID: 1] VÃ­deo processado com sucesso!
INFO - âœ… [Video ID: 2] VÃ­deo processado com sucesso!
```

## ğŸ—ï¸ Arquitetura

```
src/
â”œâ”€â”€ domain/                    # Entidades do domÃ­nio
â”‚   â””â”€â”€ entities/
â”‚       â”œâ”€â”€ video_entity.py    # Entidade de vÃ­deo (com campos do banco)
â”‚       â””â”€â”€ user_entity.py     # Entidade de usuÃ¡rio
â”‚
â”œâ”€â”€ application/               # LÃ³gica de negÃ³cio
â”‚   â”œâ”€â”€ ports/                # Interfaces (contratos)
â”‚   â”‚   â”œâ”€â”€ storage_port.py
â”‚   â”‚   â”œâ”€â”€ message_producer_port.py
â”‚   â”‚   â””â”€â”€ repository_port.py  # Port para acesso ao banco
â”‚   â”œâ”€â”€ services/             # ServiÃ§os de domÃ­nio
â”‚   â”‚   â””â”€â”€ video_processing_service.py
â”‚   â””â”€â”€ use_cases/            # Casos de uso
â”‚       â””â”€â”€ process_video_use_case.py
â”‚
â”œâ”€â”€ adapters/                 # ImplementaÃ§Ãµes dos ports
â”‚   â”œâ”€â”€ input/               # Entrada (driving)
â”‚   â”‚   â”œâ”€â”€ consumers/
â”‚   â”‚   â”‚   â””â”€â”€ kafka_consumer.py
â”‚   â”‚   â””â”€â”€ routers/
â”‚   â”‚       â””â”€â”€ health_controller.py
â”‚   â””â”€â”€ output/              # SaÃ­da (driven)
â”‚       â”œâ”€â”€ persistence/
â”‚       â”‚   â”œâ”€â”€ database_connection.py    # ConexÃ£o PostgreSQL
â”‚       â”‚   â”œâ”€â”€ repositories/
â”‚       â”‚   â”‚   â””â”€â”€ video_repository.py   # RepositÃ³rio de vÃ­deos
â”‚       â”‚   â””â”€â”€ s3/
â”‚       â”‚       â””â”€â”€ s3_client.py
â”‚       â””â”€â”€ producers/
â”‚           â””â”€â”€ kafka_producer.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py           # ConfiguraÃ§Ãµes
â””â”€â”€ main.py                   # Ponto de entrada
```

## ğŸš€ Executando a AplicaÃ§Ã£o

### 1. Inicie os serviÃ§os necessÃ¡rios:

```powershell
# PostgreSQL deve estar rodando
# Kafka deve estar rodando
```

### 2. Inicie a aplicaÃ§Ã£o:

```powershell
python -m src.main
```

O servidor estarÃ¡ disponÃ­vel em: http://localhost:3000

**Endpoints disponÃ­veis:**
- `GET /video-processor/health` - Healthcheck para EKS/Docker
- `GET /video-processor/apidocs` - DocumentaÃ§Ã£o interativa (Swagger)
**Endpoints disponÃ­veis:**
- `GET /video-processor/health` - Healthcheck para EKS/Docker
- `GET /video-processor/apidocs` - DocumentaÃ§Ã£o interativa (Swagger)

### 3. Verifique o healthcheck:

```powershell
# PowerShell
Invoke-WebRequest http://localhost:3000/video-processor/health

# Ou no navegador:
# http://localhost:3000/video-processor/health
# http://localhost:3000/video-processor/apidocs
```

### 4. Envie mensagens de teste:

```powershell
# Use o kafka-console-producer
kafka-console-producer --broker-list localhost:9092 --topic video-events
```

Digite as mensagens JSON (uma por linha):
```json
{"video_id": "uuid-do-video", "path": "video/teste-1.mp4"}
{"video_id": "uuid-do-video-2", "path": "video/teste-2.mp4"}
```

Para parar, pressione `Ctrl+C`

## ğŸ“ Logs

A aplicaÃ§Ã£o gera logs detalhados para cada vÃ­deo processado:

```
INFO - ğŸš€ Iniciando aplicaÃ§Ã£o...
INFO - âœ… ConexÃ£o com PostgreSQL estabelecida
INFO - âœ… ThreadPoolExecutor inicializado com 3 workers
INFO - âœ… S3 Client inicializado
INFO - âœ… Kafka Producer inicializado
INFO - âœ… Video Processing Service inicializado
INFO - âœ… Process Video Use Case inicializado
INFO - âœ… Kafka Consumer inicializado
INFO - ğŸ‰ AplicaÃ§Ã£o iniciada com sucesso!

INFO - ğŸ¬ [Video ID: uuid-123] Tarefa submetida para processamento
INFO - ğŸ“Š Tarefas em processamento: ~1
INFO - === [Thread-ThreadPoolExecutor-0_0] Processando vÃ­deo ===
INFO - Video ID: uuid-123
INFO - VÃ­deo encontrado: Meu VÃ­deo Teste
INFO - UsuÃ¡rio: JoÃ£o Silva (joao@email.com)
INFO - Status atualizado para: 2 (Processando)
INFO - VÃ­deo carregado: 300 frames, 30.0 FPS
INFO - Extraindo frames nas posiÃ§Ãµes: [0, 100, 200, 299]
INFO - 4 frames extraÃ­dos com sucesso
INFO - ZIP criado com sucesso
INFO - ZIP enviado com sucesso para S3: zip/teste.zip
INFO - Status atualizado para: 3 (Finalizado)
INFO - âœ… [Video ID: uuid-123] VÃ­deo processado com sucesso!
```

## ğŸ³ Deploy com Docker

### Build da imagem:

```powershell
docker build -t video-processor:latest .
```

### Executar com Docker:

```powershell
docker run -d \
  --name video-processor \
  -p 3000:3000 \
  --env-file .env \
  video-processor:latest
```

### Executar com Docker Compose:

```powershell
docker-compose up -d
```

### Verificar logs:

```powershell
docker logs -f video-processor
```

## ğŸ“ Estrutura do Projeto

```
hackaton-soat11-videoprc/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                # Ponto de entrada
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â””â”€â”€ entities/
â”‚   â”‚       â”œâ”€â”€ video_entity.py
â”‚   â”‚       â””â”€â”€ user_entity.py
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ ports/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ use_cases/
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ output/
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ settings.py
â”œâ”€â”€ tests/
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ†˜ Troubleshooting

### Erro de conexÃ£o com PostgreSQL
- Verifique se o PostgreSQL estÃ¡ rodando
- Confirme as credenciais em `DB_USER` e `DB_PASSWORD`
- Verifique se o banco de dados `cliptozip` existe
- Confirme que as tabelas foram criadas corretamente

### VÃ­deo nÃ£o processado
- Verifique se o vÃ­deo existe no banco com status = 1
- Confirme que o `video_id` na mensagem Kafka estÃ¡ correto
- Verifique se hÃ¡ relaÃ§Ã£o com usuÃ¡rio vÃ¡lido (FK)

### Erro de conexÃ£o com Kafka
- Verifique se o Kafka estÃ¡ rodando
- Confirme o endereÃ§o em `KAFKA_BOOTSTRAP_SERVERS`
- Verifique se os tÃ³picos foram criados

### Erro de acesso ao S3
- Valide suas credenciais AWS
- Verifique as permissÃµes IAM do bucket
- Confirme que o bucket existe na regiÃ£o especificada

### Arquivo nÃ£o encontrado no S3
- Verifique se o path na mensagem estÃ¡ correto
- Confirme que o arquivo existe no bucket configurado
- Certifique-se que o path nÃ£o comeÃ§a com `/`

### Erro ao processar vÃ­deo
- Verifique se o arquivo Ã© um vÃ­deo vÃ¡lido (mp4, avi, etc.)
- Confirme que o OpenCV estÃ¡ instalado: `pip install opencv-python`
- Verifique os logs para detalhes especÃ­ficos do erro

### Processamento lento
- Aumente `MAX_WORKERS` no `.env` (cuidado com recursos do sistema)
- Verifique a conexÃ£o com S3 (latÃªncia de rede)
- Considere usar instÃ¢ncias com mais CPU/memÃ³ria

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a especificada no arquivo LICENSE.
  -p 8000:8000 \
  --env-file .env \
  video-processor:latest
```

### Executar com Docker Compose:

```powershell
docker-compose up -d
```

### Verificar logs:

```powershell
docker logs -f video-processor
```

## â˜¸ï¸ Deploy no Kubernetes/EKS

### 1. Edite o arquivo k8s-deployment.yaml com suas configuraÃ§Ãµes

### 2. Aplique os recursos:

```powershell
kubectl apply -f k8s-deployment.yaml
```

### 3. Verifique o status:3000/video-processor/health

# Ou no navegador:
# http://localhost:3000/video-processor/health
# http://localhost:3000/video-processor/apidocs
```

### 4. Envie mensagens de teste:

```powershell
# Use o kafka-console-producer
kafka-console-producer --broker-list localhost:9092 --topic video-events
```

Digite as mensagens JSON (uma por linha):
```json
{"video_id": "1", "path": "video/teste-1.mp4"}
{"video_id": "2", "path": "video/teste-2.mp4"}
{"video_id": "3", "path": "video/teste-3.mp4"}
```detalhados para cada vÃ­deo processado:

```
INFO - ğŸš€ Iniciando aplicaÃ§Ã£o...
INFO - âœ… ThreadPoolExecutor inicializado com 3 workers
INFO - âœ… S3 Client inicializado
INFO - âœ… Kafka Producer inicializado
INFO - âœ… Video Processing Service inicializado
INFO - âœ… Process Video Use Case inicializado
INFO - âœ… Kafka Consumer inicializado
INFO - ğŸ‰ AplicaÃ§Ã£o iniciada com sucesso!

INFO - ğŸ¬ [Video ID: 1] Tarefa submetida para processamento
INFO - ğŸ“Š Tarefas em processamento: ~1
INFO - === [Thread-ThreadPoolExecutor-0_0] Processando vÃ­deo ===
INFO - Video ID: 1
INFO - Path: video/teste.mp4
INFO - Obtendo conteÃºdo do arquivo video/teste.mp4 do S3...
INFO - VÃ­deo carregado: 300 frames, 30.0 FPS
INFO - Extraindo frames nas posiÃ§Ãµes: [0, 100, 200, 299]
INFO - Frame 1/4 extraÃ­do
INFO - Frame 2/4 extraÃ­do
INFO - Frame 3/4 extraÃ­do
INFO - Frame 4/4 extraÃ­do
- Verifique se os tÃ³picos foram criados

### Erro de acesso ao S3
- Valide suas credenciais AWS
- Verifique as permissÃµes IAM do bucket
- Confirme que o bucket existe na regiÃ£o especificada

### Arquivo nÃ£o encontrado no S3
- Verifique se o path na mensagem estÃ¡ correto
- Confirme que o arquivo existe no bucket configurado
- Certifique-se que o path nÃ£o comeÃ§a com `/`

### Erro ao processar vÃ­deo
- Verifique se o arquivo Ã© um vÃ­deo vÃ¡lido (mp4, avi, etc.)
- Confirme que o OpenCV estÃ¡ instalado: `pip install opencv-python`
- Verifique os logs para detalhes especÃ­ficos do erro

### Processamento lento
- Aumente `MAX_WORKERS` no `.env` (cuidado com recursos do sistema)
- Verifique a conexÃ£o com S3 (latÃªncia de rede)
- Considere usar instÃ¢ncias com mais CPU/memÃ³ria

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [IMPLEMENTATION_GUIDE.md](IMPLEMENTATION_GUIDE.md) - Guia completo de implementaÃ§Ã£o e arquitetura
# Com Docker
docker-compose up -d kafka
```

### 2. Inicie a aplicaÃ§Ã£o:

```powershell
python -m src.main
```

### 3. Verifique o healthcheck:

```powershell
# PowerShell
Invoke-WebRequest http://localhost:8000/health

# Ou no navegador:
# http://localhost:8000/health
# http://localhost:8000/docs
```

### 4. Envie uma mensagem de teste:

```powershell
# Use o kafka-console-producer ou sua ferramenta preferida
kafka-console-producer --broker-list localhost:9092 --topic video-events

# Digite a mensagem JSON:
{"s3_key": "test/video.mp4"}
```

## ğŸ“ Logs

A aplicaÃ§Ã£o gera logs no formato:

```
2026-01-09 20:00:00 - src.kafka_consumer - INFO - Mensagem recebida: {'s3_key': 'videos/test.mp4'}
2026-01-09 20:00:01 - src.s3_client - INFO - Obtendo conteÃºdo do arquivo videos/test.mp4 do S3...
2026-01-09 20:00:02 - src.s3_client - INFO - Arquivo videos/test.mp4 lido com sucesso (1024000 bytes)
```

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a especificada no arquivo LICENSE.

## ğŸ†˜ Troubleshooting

### Erro de conexÃ£o com Kafka
- Verifique se o Kafka estÃ¡ rodando
- Confirme o endereÃ§o em `KAFKA_BOOTSTRAP_SERVERS`

### Erro de acesso ao S3
- Valide suas credenciais AWS
- Verifique as permissÃµes IAM do bucket
- Confirme que o bucket existe na regiÃ£o especificada

### Arquivo nÃ£o encontrado no S3
- Verifique se o campo `s3_key` na mensagem estÃ¡ correto
- Confirme que o arquivo existe no bucket configurado