# Hackaton SOAT11 - Video Processor

AplicaÃ§Ã£o Python para processar vÃ­deos do S3, extraindo frames e gerando arquivos ZIP, com processamento paralelo via **AWS SQS** e integraÃ§Ã£o com PostgreSQL.

## ğŸ“‹ DescriÃ§Ã£o

Esta aplicaÃ§Ã£o roda um servidor FastAPI que:
- Escuta mensagens do **AWS SQS** com informaÃ§Ãµes de vÃ­deos
- Gerencia processamento de vÃ­deos com banco de dados PostgreSQL (RDS)
- Controla status de processamento (aguardando, processando, finalizado, erro)
- Baixa vÃ­deos do AWS S3
- Extrai frames distribuÃ­dos ao longo do vÃ­deo (inÃ­cio, meio e fim)
- Gera arquivo ZIP com as imagens
- Faz upload do ZIP no S3
- Envia mensagem de conclusÃ£o com dados do usuÃ¡rio para fila SQS de saÃ­da
- **Processa mÃºltiplos vÃ­deos simultaneamente**

## ğŸš€ Funcionalidades

- âœ… **Processamento Paralelo** - Processa mÃºltiplos vÃ­deos ao mesmo tempo
- âœ… **IntegraÃ§Ã£o com AWS SQS** - Mensageria escalÃ¡vel e gerenciada
- âœ… **IntegraÃ§Ã£o com PostgreSQL (RDS)** - Controle de status e dados de vÃ­deos/usuÃ¡rios
- âœ… Servidor FastAPI com healthcheck para EKS/Docker
- âœ… Consumer SQS rodando em background com long polling
- âœ… ExtraÃ§Ã£o inteligente de frames (inÃ­cio, meio e fim do vÃ­deo)
- âœ… GeraÃ§Ã£o automÃ¡tica de ZIP com frames
- âœ… Upload automÃ¡tico no S3 (pasta `zip/`)
- âœ… Producer SQS para notificaÃ§Ã£o de conclusÃ£o com dados do usuÃ¡rio
- âœ… Tratamento de erros com atualizaÃ§Ã£o de status
- âœ… Arquitetura Hexagonal (Ports & Adapters)
- âœ… Logging detalhado por vÃ­deo
- âœ… ValidaÃ§Ã£o de configuraÃ§Ãµes
- âœ… DocumentaÃ§Ã£o automÃ¡tica (Swagger)
- âœ… Infraestrutura como CÃ³digo (Terraform)

## ğŸ“¦ PrÃ©-requisitos

- Python 3.8+
- PostgreSQL 12+ (RDS ou local para desenvolvimento)
- Conta AWS com acesso ao SQS e S3
- OpenCV (incluÃ­do no requirements.txt)
- Ambiente virtual Python (recomendado)

### Para Desenvolvimento Local
- Docker e Docker Compose (para LocalStack e PostgreSQL)
- AWS CLI configurado

## ğŸ”§ InstalaÃ§Ã£o

1. Clone o repositÃ³rio e ative o ambiente virtual:

```powershell
cd hackaton-soat11-videoprc
.venv\Scripts\activate
```

2. Instale as dependÃªncias:

```powershell
pip install -r requirements.txt
```

3. Configure as variÃ¡veis de ambiente:

```powershell
# Copie o arquivo de exemplo
Copy-Item .env.example .env

# Edite o arquivo .env com suas configuraÃ§Ãµes
```

## âš™ï¸ ConfiguraÃ§Ã£o

Edite o arquivo `.env` com suas credenciais e configuraÃ§Ãµes:

### Para ProduÃ§Ã£o (AWS Real)
```env
# AWS SQS
SQS_INPUT_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/123456789012/video-input-queue
SQS_OUTPUT_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/123456789012/video-output-queue

# AWS S3
AWS_ACCESS_KEY_ID=sua_access_key
AWS_SECRET_ACCESS_KEY=sua_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=seu-bucket

# PostgreSQL Database (RDS)
DB_HOST=seu-rds-endpoint.us-east-1.rds.amazonaws.com
DB_PORT=5432
DB_NAME=videoprocessor
DB_USER=postgres
DB_PASSWORD=sua-senha-segura

# AplicaÃ§Ã£o
LOG_LEVEL=INFO
APP_NAME=video-processor-api
MAX_WORKERS=3  # NÃºmero de vÃ­deos processando simultaneamente
```

### Para Desenvolvimento Local (com LocalStack)
```env
# AWS SQS
SQS_INPUT_QUEUE_URL=http://localhost:4566/000000000000/video-input-queue
SQS_OUTPUT_QUEUE_URL=http://localhost:4566/000000000000/video-output-queue

# AWS (LocalStack)
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test
AWS_REGION=us-east-1
S3_BUCKET_NAME=video-bucket-local

# PostgreSQL Database (local)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=videoprocessor
DB_USER=postgres
DB_PASSWORD=postgres

# AplicaÃ§Ã£o
LOG_LEVEL=INFO
APP_NAME=video-processor-api
MAX_WORKERS=3
```

## ğŸ—„ï¸ Banco de Dados

### Estrutura das Tabelas

#### Tabela: cliptozip.videos

```sql
CREATE TABLE cliptozip.videos (
    video_id uuid NOT NULL,
    user_id uuid NOT NULL,
    data_video_up timestamp DEFAULT CURRENT_TIMESTAMP NOT NULL,
    status int4 NOT NULL,
    video_name varchar(200) NULL,
    zip_name varchar(200) NULL,
    descricao varchar(500) NULL,
    titulo varchar(150) NULL,
    metadados jsonb NULL,
    CONSTRAINT videos_pkey PRIMARY KEY (video_id),
    CONSTRAINT videos_user_fk FOREIGN KEY (user_id) REFERENCES cliptozip."user"(user_id)
);
```

#### Tabela: cliptozip.user

```sql
CREATE TABLE cliptozip."user" (
    user_id uuid DEFAULT gen_random_uuid() NOT NULL,
    "name" varchar(255) NULL,
    email varchar(255) NOT NULL,
    password_hash varchar(255) NOT NULL,
    created_at timestamptz DEFAULT now() NOT NULL,
    CONSTRAINT user_pkey PRIMARY KEY (user_id)
);
CREATE INDEX idx_app_user_email ON cliptozip."user" USING btree (email);
```

### Status dos VÃ­deos

| Status | DescriÃ§Ã£o |
|--------|-----------|
| 1 | Aguardando processamento |
| 2 | Processando |
| 3 | Finalizado com sucesso |
| 4 | Erro no processamento |

## ğŸ“¨ Mensagens SQS

### Mensagem de Entrada (Fila: video-input-queue)

```json
{
  "video_id": "uuid-do-video",
  "path": "video/nome-do-video.mp4"
}
```

### Mensagem de SaÃ­da - Sucesso (Fila: video-output-queue)

```json
{
  "titulo": "Nome do vÃ­deo",
  "status": "Finalizado",
  "mensagem": "Seu zip estÃ¡ pronto para download",
  "emailUsuario": "usuario@email.com",
  "nomeUsuario": "Nome do UsuÃ¡rio"
}
```

### Mensagem de SaÃ­da - Erro (Fila: video-output-queue)

```json
{
  "titulo": "Nome do vÃ­deo",
  "status": "Erro",
  "mensagem": "Houve um erro no processamento do seu vÃ­deo",
  "emailUsuario": "usuario@email.com",
  "nomeUsuario": "Nome do UsuÃ¡rio"
}
```

## ğŸ”„ Fluxo de Processamento

```
ğŸ“¥ SQS (video-input-queue) - Recebe video_id e path
    â†“
ğŸ” Busca vÃ­deo e usuÃ¡rio no PostgreSQL pelo video_id
    â†“
âœ… Valida status = 1 (aguardando processamento)
    â†“
ğŸ”„ Atualiza status = 2 (processando)
    â†“
ğŸ“¦ Download vÃ­deo do S3
    â†“
ğŸ¬ ExtraÃ§Ã£o de 4 frames (inÃ­cio, meio, fim)
    â†“
ğŸ“¦ CriaÃ§Ã£o de arquivo ZIP com frames
    â†“
â˜ï¸ Upload do ZIP para S3 (pasta zip/)
    â†“
âœ… Sucesso: Status = 3 + salva zip_name + envia mensagem com dados do usuÃ¡rio
âŒ Erro: Status = 4 + envia mensagem de erro com dados do usuÃ¡rio
    â†“
ğŸ“¤ SQS (video-output-queue) - NotificaÃ§Ã£o ao usuÃ¡rio
    â†“
ğŸ—‘ï¸ Mensagem deletada da fila de entrada
```

### ğŸ¯ ExtraÃ§Ã£o de Frames

Os frames sÃ£o extraÃ­dos de forma distribuÃ­da:
- **Frame 1**: InÃ­cio do vÃ­deo (frame 0)
- **Frame 2**: Meio do vÃ­deo (~33%)
- **Frame 3**: Meio-fim do vÃ­deo (~66%)
- **Frame 4**: Final do vÃ­deo (Ãºltimo frame)

Exemplo: VÃ­deo com 300 frames â†’ Extrai frames: 0, 100, 200, 299

## âš¡ Processamento Paralelo

A aplicaÃ§Ã£o utiliza **ThreadPoolExecutor** para processar mÃºltiplos vÃ­deos simultaneamente:

- Configure `MAX_WORKERS` no `.env` (padrÃ£o: 3)
- Cada vÃ­deo Ã© processado em uma thread separada
- O Consumer Kafka nÃ£o bloqueia durante o processamento
- Logs identificam qual thread estÃ¡ processando cada vÃ­deo

**Exemplo de log com processamento paralelo:**
```
INFO - ğŸ¬ [Video ID: 1] Tarefa submetida para processamento
INFO - ğŸ¬ [Video ID: 2] Tarefa submetida para processamento
INFO - ğŸ“Š Tarefas em processamento: ~2
INFO - [Thread-1] Processando vÃ­deo - Video ID: 1
INFO - [Thread-2] Processando vÃ­deo - Video ID: 2
INFO - âœ… [Video ID: 1] VÃ­deo processado com sucesso!
INFO - âœ… [Video ID: 2] VÃ­deo processado com sucesso!
```

## ğŸ—ï¸ Arquitetura

```
src/
â”œâ”€â”€ domain/                    # Entidades do domÃ­nio
â”‚   â””â”€â”€ entities/
â”‚       â”œâ”€â”€ video_entity.py    # Entidade de vÃ­deo (com campos do banco)
â”‚       â””â”€â”€ user_entity.py     # Entidade de usuÃ¡rio
â”‚
â”œâ”€â”€ application/               # LÃ³gica de negÃ³cio
â”‚   â”œâ”€â”€ ports/                # Interfaces (contratos)
â”‚   â”‚   â”œâ”€â”€ storage_port.py
â”‚   â”‚   â”œâ”€â”€ message_producer_port.py
â”‚   â”‚   â””â”€â”€ repository_port.py  # Port para acesso ao banco
â”‚   â”œâ”€â”€ services/             # ServiÃ§os de domÃ­nio
â”‚   â”‚   â””â”€â”€ video_processing_service.py
â”‚   â””â”€â”€ use_cases/            # Casos de uso
â”‚       â””â”€â”€ process_video_use_case.py
â”‚
â”œâ”€â”€ adapters/                 # ImplementaÃ§Ãµes dos ports
â”‚   â”œâ”€â”€ input/               # Entrada (driving)
â”‚   â”‚   â”œâ”€â”€ consumers/
â”‚   â”‚   â”‚   â””â”€â”€ kafka_consumer.py
â”‚   â”‚   â””â”€â”€ routers/
â”‚   â”‚       â””â”€â”€ health_controller.py
â”‚   â””â”€â”€ output/              # SaÃ­da (driven)
â”‚       â”œâ”€â”€ persistence/
â”‚       â”‚   â”œâ”€â”€ database_connection.py    # ConexÃ£o PostgreSQL
â”‚       â”‚   â”œâ”€â”€ repositories/
â”‚       â”‚   â”‚   â””â”€â”€ video_repository.py   # RepositÃ³rio de vÃ­deos
â”‚       â”‚   â””â”€â”€ s3/
â”‚       â”‚       â””â”€â”€ s3_client.py
â”‚       â””â”€â”€ producers/
â”‚           â””â”€â”€ sqs_producer.py          # Producer SQS
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py           # ConfiguraÃ§Ãµes
â””â”€â”€ main.py                   # Ponto de entrada
```

## ğŸš€ Executando a AplicaÃ§Ã£o

### OpÃ§Ã£o 1: Desenvolvimento Local (com LocalStack)

#### 1. Inicie os serviÃ§os Docker:

```powershell
docker-compose up -d
```

Isso iniciarÃ¡:
- PostgreSQL (porta 5432)
- LocalStack (porta 4566) - simula SQS e S3

#### 2. Inicialize recursos AWS no LocalStack:

```powershell
# PowerShell
.\scripts\init-localstack.ps1

# Bash (Linux/Mac)
chmod +x ./scripts/init-localstack.sh
./scripts/init-localstack.sh
```

#### 3. Configure o `.env` conforme mostrado na seÃ§Ã£o de configuraÃ§Ã£o

#### 4. Inicie a aplicaÃ§Ã£o:

```powershell
python -m src.main
```

O servidor estarÃ¡ disponÃ­vel em: http://localhost:3000

**Endpoints disponÃ­veis:**
- `GET /video-processor-api/health` - Healthcheck para EKS/Docker
- `GET /video-processor-api/apidocs` - DocumentaÃ§Ã£o interativa (Swagger)

#### 5. Verifique o healthcheck:

```powershell
# PowerShell
Invoke-WebRequest http://localhost:3000/video-processor-api/health

# Ou no navegador:
# http://localhost:3000/video-processor-api/health
# http://localhost:3000/video-processor-api/apidocs
```

#### 6. Envie mensagens de teste para SQS:

```powershell
# PowerShell - LocalStack
aws --endpoint-url=http://localhost:4566 sqs send-message `
  --queue-url http://localhost:4566/000000000000/video-input-queue `
  --message-body '{"video_id": "uuid-do-video", "path": "video/teste.mp4"}'
```

### OpÃ§Ã£o 2: ProduÃ§Ã£o (AWS Real)

#### 1. Provisione a infraestrutura AWS com Terraform:

```bash
cd terraform
terraform init
terraform plan
terraform apply
```

Veja detalhes em [terraform/README.md](terraform/README.md)

#### 2. Configure o `.env` com os valores reais da AWS

Use os outputs do Terraform para preencher as variÃ¡veis de ambiente.

#### 3. Inicie a aplicaÃ§Ã£o:

```bash
python -m src.main
```

#### 4. Envie mensagens para SQS (AWS Real):

```bash
aws sqs send-message \
  --queue-url https://sqs.us-east-1.amazonaws.com/123456789012/video-input-queue \
  --message-body '{"video_id": "uuid-do-video", "path": "video/teste.mp4"}'
```

Para parar, pressione `Ctrl+C`

## ğŸ“ Logs

A aplicaÃ§Ã£o gera logs detalhados para cada vÃ­deo processado:

```
INFO - ğŸš€ Iniciando aplicaÃ§Ã£o...
INFO - âœ… ConexÃ£o com PostgreSQL estabelecida
INFO - âœ… ThreadPoolExecutor inicializado com 3 workers
INFO - âœ… S3 Client inicializado
INFO - âœ… SQS Producer inicializado
INFO - âœ… Video Processing Service inicializado
INFO - âœ… Process Video Use Case inicializado
INFO - âœ… SQS Consumer inicializado
INFO - ğŸ‰ AplicaÃ§Ã£o iniciada com sucesso!

INFO - ğŸ¬ [Video ID: uuid-123] Tarefa submetida para processamento
INFO - ğŸ“Š Tarefas em processamento: ~1
INFO - === [Thread-ThreadPoolExecutor-0_0] Processando vÃ­deo ===
INFO - Video ID: uuid-123
INFO - VÃ­deo encontrado: Meu VÃ­deo Teste
INFO - UsuÃ¡rio: JoÃ£o Silva (joao@email.com)
INFO - Status atualizado para: 2 (Processando)
INFO - VÃ­deo carregado: 300 frames, 30.0 FPS
INFO - Extraindo frames nas posiÃ§Ãµes: [0, 100, 200, 299]
INFO - 4 frames extraÃ­dos com sucesso
INFO - ZIP criado com sucesso
INFO - ZIP enviado com sucesso para S3: zip/teste.zip
INFO - Status atualizado para: 3 (Finalizado)
INFO - âœ… [Video ID: uuid-123] VÃ­deo processado com sucesso!
```

## ğŸ³ Deploy com Docker

### Build da imagem:

```powershell
docker build -t video-processor:latest .
```

### Executar com Docker:

```powershell
docker run -d \
  --name video-processor \
  -p 3000:3000 \
  --env-file .env \
  video-processor:latest
```

### Executar com Docker Compose:

```powershell
docker-compose up -d
```

### Verificar logs:

```powershell
docker logs -f video-processor
```

## ğŸ“ Estrutura do Projeto

```
hackaton-soat11-videoprc/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                # Ponto de entrada
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â””â”€â”€ entities/
â”‚   â”‚       â”œâ”€â”€ video_entity.py
â”‚   â”‚       â””â”€â”€ user_entity.py
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ ports/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ use_cases/
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ output/
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ settings.py
â”œâ”€â”€ tests/
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ†˜ Troubleshooting

### Erro de conexÃ£o com PostgreSQL
- Verifique se o PostgreSQL estÃ¡ rodando
- Confirme as credenciais em `DB_USER` e `DB_PASSWORD`
- Verifique se o banco de dados `cliptozip` existe
- Confirme que as tabelas foram criadas corretamente

### VÃ­deo nÃ£o processado
- Verifique se o vÃ­deo existe no banco com status = 1
- Confirme que o `video_id` na mensagem Kafka estÃ¡ correto
- Verifique se hÃ¡ relaÃ§Ã£o com usuÃ¡rio vÃ¡lido (FK)

### Erro de conexÃ£o com Kafka
- Verifique se o Kafka estÃ¡ rodando
- Confirme o endereÃ§o em `KAFKA_BOOTSTRAP_SERVERS`
- Verifique se os tÃ³picos foram criados

### Erro de acesso ao S3
- Valide suas credenciais AWS
- Verifique as permissÃµes IAM do bucket
- Confirme que o bucket existe na regiÃ£o especificada

### Arquivo nÃ£o encontrado no S3
- Verifique se o path na mensagem estÃ¡ correto
- Confirme que o arquivo existe no bucket configurado
- Certifique-se que o path nÃ£o comeÃ§a com `/`

### Erro ao processar vÃ­deo
- Verifique se o arquivo Ã© um vÃ­deo vÃ¡lido (mp4, avi, etc.)
- Confirme que o OpenCV estÃ¡ instalado: `pip install opencv-python`
- Verifique os logs para detalhes especÃ­ficos do erro

### Processamento lento
- Aumente `MAX_WORKERS` no `.env` (cuidado com recursos do sistema)
- Verifique a conexÃ£o com S3 (latÃªncia de rede)
- Considere usar instÃ¢ncias com mais CPU/memÃ³ria

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a especificada no arquivo LICENSE.
  -p 8000:8000 \
  --env-file .env \
  video-processor:latest
```

### Executar com Docker Compose:

```powershell
docker-compose up -d
```

### Verificar logs:

```powershell
docker logs -f video-processor
```

## â˜¸ï¸ Deploy no Kubernetes/EKS

### 1. Edite o arquivo k8s-deployment.yaml com suas configuraÃ§Ãµes

### 2. Aplique os recursos:

```powershell
kubectl apply -f k8s-deployment.yaml
```

### 3. Verifique o status:3000/video-processor/health

# Ou no navegador:
# http://localhost:3000/video-processor/health
# http://localhost:3000/video-processor/apidocs
```

### 4. Envie mensagens de teste:

```powershell
# Use o kafka-console-producer
kafka-console-producer --broker-list localhost:9092 --topic video-events
```

Digite as mensagens JSON (uma por linha):
```json
{"video_id": "1", "path": "video/teste-1.mp4"}
{"video_id": "2", "path": "video/teste-2.mp4"}
{"video_id": "3", "path": "video/teste-3.mp4"}
```detalhados para cada vÃ­deo processado:

```
INFO - ğŸš€ Iniciando aplicaÃ§Ã£o...
INFO - âœ… ThreadPoolExecutor inicializado com 3 workers
INFO - âœ… S3 Client inicializado
INFO - âœ… Kafka Producer inicializado
INFO - âœ… Video Processing Service inicializado
INFO - âœ… Process Video Use Case inicializado
INFO - âœ… Kafka Consumer inicializado
INFO - ğŸ‰ AplicaÃ§Ã£o iniciada com sucesso!

INFO - ğŸ¬ [Video ID: 1] Tarefa submetida para processamento
INFO - ğŸ“Š Tarefas em processamento: ~1
INFO - === [Thread-ThreadPoolExecutor-0_0] Processando vÃ­deo ===
INFO - Video ID: 1
INFO - Path: video/teste.mp4
INFO - Obtendo conteÃºdo do arquivo video/teste.mp4 do S3...
INFO - VÃ­deo carregado: 300 frames, 30.0 FPS
INFO - Extraindo frames nas posiÃ§Ãµes: [0, 100, 200, 299]
INFO - Frame 1/4 extraÃ­do
INFO - Frame 2/4 extraÃ­do
INFO - Frame 3/4 extraÃ­do
INFO - Frame 4/4 extraÃ­do
- Verifique se os tÃ³picos foram criados

### Erro de acesso ao S3
- Valide suas credenciais AWS
- Verifique as permissÃµes IAM do bucket
- Confirme que o bucket existe na regiÃ£o especificada

### Arquivo nÃ£o encontrado no S3
- Verifique se o path na mensagem estÃ¡ correto
- Confirme que o arquivo existe no bucket configurado
- Certifique-se que o path nÃ£o comeÃ§a com `/`

### Erro ao processar vÃ­deo
- Verifique se o arquivo Ã© um vÃ­deo vÃ¡lido (mp4, avi, etc.)
- Confirme que o OpenCV estÃ¡ instalado: `pip install opencv-python`
- Verifique os logs para detalhes especÃ­ficos do erro

### Processamento lento
- Aumente `MAX_WORKERS` no `.env` (cuidado com recursos do sistema)
- Verifique a conexÃ£o com S3 (latÃªncia de rede)
- Considere usar instÃ¢ncias com mais CPU/memÃ³ria

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [IMPLEMENTATION_GUIDE.md](IMPLEMENTATION_GUIDE.md) - Guia completo de implementaÃ§Ã£o e arquitetura
# Com Docker
docker-compose up -d kafka
```

### 2. Inicie a aplicaÃ§Ã£o:

```powershell
python -m src.main
```

### 3. Verifique o healthcheck:

```powershell
# PowerShell
Invoke-WebRequest http://localhost:8000/health

# Ou no navegador:
# http://localhost:8000/health
# http://localhost:8000/docs
```

### 4. Envie uma mensagem de teste:

```powershell
# Use o kafka-console-producer ou sua ferramenta preferida
kafka-console-producer --broker-list localhost:9092 --topic video-events

# Digite a mensagem JSON:
{"s3_key": "test/video.mp4"}
```

## ğŸ“ Logs

A aplicaÃ§Ã£o gera logs no formato:

```
2026-01-09 20:00:00 - src.kafka_consumer - INFO - Mensagem recebida: {'s3_key': 'videos/test.mp4'}
2026-01-09 20:00:01 - src.s3_client - INFO - Obtendo conteÃºdo do arquivo videos/test.mp4 do S3...
2026-01-09 20:00:02 - src.s3_client - INFO - Arquivo videos/test.mp4 lido com sucesso (1024000 bytes)
```

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a especificada no arquivo LICENSE.

## ğŸ†˜ Troubleshooting

### Erro de conexÃ£o com Kafka
- Verifique se o Kafka estÃ¡ rodando
- Confirme o endereÃ§o em `KAFKA_BOOTSTRAP_SERVERS`

### Erro de acesso ao S3
- Valide suas credenciais AWS
- Verifique as permissÃµes IAM do bucket
- Confirme que o bucket existe na regiÃ£o especificada

### Arquivo nÃ£o encontrado no S3
- Verifique se o campo `s3_key` na mensagem estÃ¡ correto
- Confirme que o arquivo existe no bucket configurado
##  Documentaï¿½ï¿½o Adicional

- [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md) - Guia completo de migraï¿½ï¿½o do Kafka para SQS
- [terraform/README.md](terraform/README.md) - Como provisionar infraestrutura AWS com Terraform

##  Migraï¿½ï¿½o do Kafka para SQS

Esta aplicaï¿½ï¿½o foi migrada do Kafka para AWS SQS. Para detalhes completos sobre:
- Mudanï¿½as realizadas
- Comparaï¿½ï¿½o Kafka vs SQS
- Instruï¿½ï¿½es de configuraï¿½ï¿½o
- Permissï¿½es IAM necessï¿½rias

Consulte: [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md)

##  Changelog

### v2.0.0 - Migraï¿½ï¿½o para AWS SQS (2026-02-04)
-  Migraï¿½ï¿½o completa de Kafka para AWS SQS
-  Adicionado suporte para LocalStack (desenvolvimento local)
-  Criados scripts de inicializaï¿½ï¿½o de recursos AWS
-  Adicionada infraestrutura como cï¿½digo (Terraform)
-  Removidas todas as dependï¿½ncias do Kafka
-  Atualizada documentaï¿½ï¿½o completa

### v1.0.0 - Versï¿½o inicial com Kafka
-  Processamento de vï¿½deos com Kafka
-  Integraï¿½ï¿½o com PostgreSQL
-  Extraï¿½ï¿½o de frames e geraï¿½ï¿½o de ZIP
-  Upload para S3
